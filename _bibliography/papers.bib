---
---

%%%%%% Pre-Print %%%%%%

%%%%%% Reviewed %%%%%%

@inproceedings{zhan2024large,
      title={Large Language Models are Capable of Offering Cognitive Reappraisal, if Guided}, 
      author={Hongli Zhan and Allen Zheng and Yoon Kyung Lee and Jina Suh and Junyi Jessy Li and Desmond C. Ong},
      year={2024},
      eprint={2404.01288},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
    booktitle = {Proceedings of the 1st Conference on Language Modeling (to appear)},
    abbr = {COLM 2024},
    abstract = {Large language models (LLMs) have offered new opportunities for emotional support, and recent work has shown that they can produce empathic responses to people in distress. However, long-term mental well-being requires emotional self-regulation, where a one-time empathic response falls short. This work takes a first step by engaging with cognitive reappraisals, a strategy from psychology practitioners that uses language to targetedly change negative appraisals that an individual makes of the situation; such appraisals is known to sit at the root of human emotional experience. We hypothesize that psychologically grounded principles could enable such advanced psychology capabilities in LLMs, and design RESORT which consists of a series of reappraisal constitutions across multiple dimensions that can be used as LLM instructions. We conduct a first-of-its-kind expert evaluation (by clinical psychologists with M.S. or Ph.D. degrees) of an LLM's zero-shot ability to generate cognitive reappraisal responses to medium-length social media messages asking for support. This fine-grained evaluation showed that even LLMs at the 7B scale guided by RESORT are capable of generating empathic responses that can help users reappraise their situations.},
    link = {https://arxiv.org/abs/2404.01288},
    pdf = {2404.01288v1.pdf},
    code = {https://github.com/honglizhan/RESORT_cognitive_reappraisal},
    open_review = {https://openreview.net/forum?id=yK8MT91dQY},
    note = {28.8% acceptance rate}
}

@inproceedings{lee2024large,
      title={Large Language Models Produce Responses Perceived to be Empathic}, 
      author={Yoon Kyung Lee and Jina Suh and Hongli Zhan and Junyi Jessy Li and Desmond C. Ong},
      year={2024},
      eprint={2403.18148},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      abbr = {ACII 2024},
    booktitle = {Proceedings of the 12th International Conference on Affective Computing and Intelligent Interaction (to appear)},
    abstract = {Large Language Models (LLMs) have demonstrated surprising performance on many tasks, including writing supportive messages that display empathy. Here, we had these models generate empathic messages in response to posts describing common life experiences, such as workplace situations, parenting, relationships, and other anxiety- and anger-eliciting situations. Across two studies (N=192, 202), we showed human raters a variety of responses written by several models (GPT4 Turbo, Llama2, and Mistral), and had people rate these responses on how empathic they seemed to be. We found that LLM-generated responses were consistently rated as more empathic than human-written responses. Linguistic analyses also show that these models write in distinct, predictable "styles", in terms of their use of punctuation, emojis, and certain words. These results highlight the potential of using LLMs to enhance human peer support in contexts where empathy is important.},
    link = {https://arxiv.org/abs/2403.18148},
    pdf = {2403.18148v1.pdf},
    code = {https://github.com/yoonlee78/LLM_empathy_social_support},
}

@inproceedings{zhan-etal-2023-evaluating,
    title = "Evaluating Subjective Cognitive Appraisals of Emotions from Large Language Models",
    author = "Zhan, Hongli  and
      Ong, Desmond C.  and
      Li, Junyi Jessy",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.962",
    pages = "14418--14446",
    abstract = "The emotions we experience involve complex processes; besides physiological aspects, research in psychology has studied cognitive appraisals where people assess their situations subjectively, according to their own values (Scherer, 2005). Thus, the same situation can often result in different emotional experiences. While the detection of emotion is a well-established task, there is very limited work so far on the automatic prediction of cognitive appraisals. This work fills the gap by presenting CovidET-Appraisals, the most comprehensive dataset to-date that assesses 24 appraisal dimensions, each with a natural language rationale, across 241 Reddit posts. CovidET-Appraisals presents an ideal testbed to evaluate the ability of large language models {---} excelling at a wide range of NLP tasks {---} to automatically assess and explain cognitive appraisals. We found that while the best models are performant, open-sourced LLMs fall short at this task, presenting a new challenge in the future development of emotionally intelligent models. We release our dataset at https://github.com/honglizhan/CovidET-Appraisals-Public.",
    abbr = {EMNLP 2023},
    award = {Findings},
    link = {https://aclanthology.org/2023.findings-emnlp.962/},
    pdf = {2023.findings-emnlp.962.pdf},
    code = {https://github.com/honglizhan/CovidET-Appraisals-Public},
    open_review = {https://openreview.net/forum?id=68A4GE4nqf},
}

@inproceedings{sosea-etal-2023-unsupervised,
    title = "Unsupervised Extractive Summarization of Emotion Triggers",
    author = "Sosea*, Tiberiu  and
      Zhan*, Hongli  and
      Li, Junyi Jessy  and
      Caragea, Cornelia",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.531",
    pages = "9550--9569",
    abstract = "Understanding what leads to emotions during large-scale crises is important as it can provide groundings for expressed emotions and subsequently improve the understanding of ongoing disasters. Recent approaches trained supervised models to both detect emotions and explain emotion triggers (events and appraisals) via abstractive summarization. However, obtaining timely and qualitative abstractive summaries is expensive and extremely time-consuming, requiring highly-trained expert annotators. In time-sensitive, high-stake contexts, this can block necessary responses. We instead pursue unsupervised systems that extract triggers from text. First, we introduce CovidET-EXT, augmenting (Zhan et al., 2022){'}s abstractive dataset (in the context of the COVID-19 crisis) with extractive triggers. Second, we develop new unsupervised learning models that can jointly detect emotions and summarize their triggers. Our best approach, entitled Emotion-Aware Pagerank, incorporates emotion information from external sources combined with a language understanding module, and outperforms strong baselines. We release our data and code at https://github.com/tsosea2/CovidET-EXT.",
    abbr = {ACL 2023},
    award = {Main},
    link = {https://aclanthology.org/2023.acl-long.531/},
    pdf = {2023.acl-long.531.pdf},
    code = {https://github.com/tsosea2/CovidET-EXT},
    poster = {2023.acl-long.531.poster.pdf},
    slides = {2023.acl-long.531.slides.pdf},
}

@inproceedings{zhan-etal-2022-feel,
    title = "Why Do You Feel This Way? Summarizing Triggers of Emotions in Social Media Posts",
    author = "Zhan*, Hongli  and
      Sosea*, Tiberiu  and
      Caragea, Cornelia  and
      Li, Junyi Jessy",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.642",
    pages = "9436--9453",
    abstract = "Crises such as the COVID-19 pandemic continuously threaten our world and emotionally affect billions of people worldwide in distinct ways. Understanding the triggers leading to people{'}s emotions is of crucial importance. Social media posts can be a good source of such analysis, yet these texts tend to be charged with multiple emotions, with triggers scattering across multiple sentences. This paper takes a novel angle, namely, emotion detection and trigger summarization, aiming to both detect perceived emotions in text, and summarize events and their appraisals that trigger each emotion. To support this goal, we introduce CovidET (Emotions and their Triggers during Covid-19), a dataset of {\textasciitilde}1,900 English Reddit posts related to COVID-19, which contains manual annotations of perceived emotions and abstractive summaries of their triggers described in the post. We develop strong baselines to jointly detect emotions and summarize emotion triggers. Our analyses show that CovidET presents new challenges in emotion-specific summarization, as well as multi-emotion detection in long social media posts.",
    abbr = {EMNLP 2022},
    award = {Main},
    link = {https://aclanthology.org/2022.emnlp-main.642/},
    pdf = {2022.emnlp-main.642.pdf},
    code = {https://github.com/honglizhan/CovidET},
    video = {https://www.youtube.com/watch?v=qjBmgeGJmtM&t=17s&ab_channel=HongliZhan},
    poster = {2022.emnlp-main.642.poster.pdf},
    slides = {2022.emnlp-main.642.slides.pdf},
}
